{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d71e769f-5b18-43c3-9add-dd202114c994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to ../03_results/out_predictions/self_predictions_kmeans.tsv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_validate\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score, make_scorer\n",
    "import numpy as np\n",
    "\n",
    "# CLR implementation\n",
    "def clr_(data, eps=1e-6):\n",
    "    \"\"\"\n",
    "    Perform centered log-ratio (clr) normalization on a dataset.\n",
    "\n",
    "    Parameters:\n",
    "    data (pandas.DataFrame): A DataFrame with samples as rows and components as columns.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: A clr-normalized DataFrame.\n",
    "    \"\"\"\n",
    "    if (data < 0).any().any():\n",
    "        raise ValueError(\"Data should be strictly positive for clr normalization.\")\n",
    "\n",
    "    # Add small amount to cells with a value of 0\n",
    "    if (data <= 0).any().any():\n",
    "        data = data.replace(0, eps)\n",
    "\n",
    "    # Calculate the geometric mean of each row\n",
    "    gm = np.exp(data.apply(np.log).mean(axis=1))\n",
    "\n",
    "    # Perform clr transformation\n",
    "    clr_data = data.apply(np.log).subtract(np.log(gm), axis=0)\n",
    "\n",
    "    return clr_data\n",
    "\n",
    "# Directories and filenames\n",
    "input_kmeans_dir = '../03_results/out_genomic_clusters'\n",
    "target_vars_filename = 'kmeans_results.tsv'\n",
    "target_vars_path = os.path.join(input_kmeans_dir, target_vars_filename)\n",
    "biological_data_dir = '../01_data/01_biological_data/'\n",
    "results_filename = '../03_results/out_predictions/self_predictions_kmeans.tsv'\n",
    "\n",
    "# Load the kmeans target variables\n",
    "target_vars = pd.read_csv(target_vars_path, sep='\\t', index_col=0)\n",
    "\n",
    "# Define valid matrix types and minimum cluster number m\n",
    "valid_matrix_types = ['M1', 'guidi', 'salazar', 'stress']\n",
    "\n",
    "# Function to filter valid columns based on matrix type and m >= 5\n",
    "def filter_columns(column_name):\n",
    "    parts = column_name.split('_')\n",
    "    matrix_type = parts[0]\n",
    "    cluster_number = int(parts[-1].replace('kmeans', ''))\n",
    "    return matrix_type in valid_matrix_types and cluster_number >= 5\n",
    "\n",
    "# Apply the filter to get the relevant target variables\n",
    "filtered_target_vars = target_vars.loc[:, target_vars.columns.map(filter_columns)]\n",
    "\n",
    "# XGBoost Classifier setup\n",
    "xgb_classifier = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# Cross-validation setup\n",
    "n_splits = 3\n",
    "n_repeats = 1\n",
    "rskf = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=0)\n",
    "\n",
    "# Initialize label encoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Initialize results DataFrame\n",
    "results_df = pd.DataFrame()\n",
    "\n",
    "# Function to load and align predictors with target variables\n",
    "def load_and_align_predictor(matrix_type, subsample):\n",
    "    predictor_file = f\"Matrix_world_GEN_{matrix_type}_{subsample}.tsv\"\n",
    "    predictor_path = os.path.join(biological_data_dir, predictor_file)\n",
    "    \n",
    "    # Load predictor matrix\n",
    "    if os.path.exists(predictor_path):\n",
    "        predictor_matrix = pd.read_csv(predictor_path, sep='\\t', index_col=0)\n",
    "        return predictor_matrix\n",
    "    else:\n",
    "        print(f\"Warning: Predictor file {predictor_file} not found!\")\n",
    "        return None\n",
    "\n",
    "# Function to evaluate model using cross-validation\n",
    "def evaluate_model(X, y, n_splits=5):\n",
    "    # Perform cross-validation\n",
    "    scoring = {\n",
    "        'accuracy': make_scorer(accuracy_score),\n",
    "        'f1_macro': make_scorer(f1_score, average='macro')\n",
    "    }\n",
    "    \n",
    "    # Cross-validate\n",
    "    cv_results = cross_validate(xgb_classifier, X, y, cv=rskf, scoring=scoring, return_train_score=False)\n",
    "    \n",
    "    # Get average metrics\n",
    "    avg_accuracy = np.mean(cv_results['test_accuracy'])\n",
    "    avg_f1_macro = np.mean(cv_results['test_f1_macro'])\n",
    "    \n",
    "    return avg_accuracy, avg_f1_macro\n",
    "\n",
    "# Iterate over each filtered target variable\n",
    "for col in filtered_target_vars.columns:\n",
    "    # Extract matrix_type and subsample from the column name\n",
    "    parts = col.split('_')\n",
    "    matrix_type, subsample = parts[0], parts[1]\n",
    "    \n",
    "    # Load the corresponding predictor matrix\n",
    "    predictor_matrix = load_and_align_predictor(matrix_type, subsample)\n",
    "    \n",
    "    if predictor_matrix is not None:\n",
    "        # Drop NaN values from the target variable\n",
    "        target_col = filtered_target_vars[col].dropna()\n",
    "        \n",
    "        # Align samples by finding the common samples between predictors and target variables\n",
    "        common_samples = target_col.index.intersection(predictor_matrix.index)\n",
    "        aligned_target = target_col.loc[common_samples]\n",
    "        aligned_predictors = predictor_matrix.loc[common_samples]\n",
    "        \n",
    "        if not aligned_target.empty and not aligned_predictors.empty:\n",
    "            # Encode the target variable\n",
    "            y_encoded = le.fit_transform(aligned_target)\n",
    "            \n",
    "            # Handle class imbalance and ensure each class has at least 'n_splits' samples\n",
    "            unique_classes, class_counts = np.unique(y_encoded, return_counts=True)\n",
    "            X_resampled = aligned_predictors.copy()\n",
    "            y_resampled = y_encoded.copy()\n",
    "\n",
    "            for cls, count in zip(unique_classes, class_counts):\n",
    "                if count < n_splits:\n",
    "                    diff = n_splits - count\n",
    "                    cls_indices = np.where(y_encoded == cls)[0]\n",
    "                    indices_to_duplicate = np.random.choice(cls_indices, diff, replace=True)\n",
    "                    X_resampled = pd.concat([X_resampled, aligned_predictors.iloc[indices_to_duplicate]], axis=0)\n",
    "                    y_resampled = np.concatenate([y_resampled, y_encoded[indices_to_duplicate]])\n",
    "\n",
    "            # Perform cross-validation and calculate metrics\n",
    "            avg_accuracy, avg_f1_macro = evaluate_model(X_resampled, y_resampled)\n",
    "\n",
    "            # Store results\n",
    "            results_df.at[col, 'accuracy'] = avg_accuracy\n",
    "            results_df.at[col, 'f1_macro'] = avg_f1_macro\n",
    "\n",
    "# Save the results to a file\n",
    "results_df.to_csv(results_filename, sep='\\t')\n",
    "\n",
    "print(f\"Results saved to {results_filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
